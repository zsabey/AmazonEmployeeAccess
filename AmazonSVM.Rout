
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##Libraries
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.3     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ ggplot2   3.4.3     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.0
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5     ✔ rsample      1.2.0
✔ dials        1.2.0     ✔ tune         1.1.2
✔ infer        1.0.5     ✔ workflows    1.1.3
✔ modeldata    1.2.0     ✔ workflowsets 1.0.1
✔ parsnip      1.1.1     ✔ yardstick    1.2.0
✔ recipes      1.0.8     
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ scales::discard() masks purrr::discard()
✖ dplyr::filter()   masks stats::filter()
✖ recipes::fixed()  masks stringr::fixed()
✖ dplyr::lag()      masks stats::lag()
✖ yardstick::spec() masks readr::spec()
✖ recipes::step()   masks stats::step()
• Use tidymodels_prefer() to resolve common conflicts.
> library(embed)
> library(discrim)

Attaching package: ‘discrim’

The following object is masked from ‘package:dials’:

    smoothness

> library(kernlab)

Attaching package: ‘kernlab’

The following object is masked from ‘package:scales’:

    alpha

The following object is masked from ‘package:purrr’:

    cross

The following object is masked from ‘package:ggplot2’:

    alpha

> library(doParallel)
Loading required package: foreach

Attaching package: ‘foreach’

The following objects are masked from ‘package:purrr’:

    accumulate, when

Loading required package: iterators
Loading required package: parallel
> 
> cl <- makePSOCKcluster(5)
> registerDoParallel(cl)
> 
> 
> trainCsv <- read_csv("train.csv")
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> testCsv <- read_csv("test.csv")
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> trainCsv <- trainCsv %>%
+   mutate(ACTION = as.factor(ACTION))
> 
> #Create the recipe and bake it
> 
> SVM_recipe <- recipe(ACTION ~ ., data=trainCsv) %>%
+   step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
+   #step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
+   step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) #%>%
>   #step_pca(all_predictors(),threshold = .95) #pca addition
> 
> prep <- prep(SVM_recipe)
> baked <- bake(prep, new_data = NULL)
> baked
# A tibble: 32,769 × 10
   RESOURCE MGR_ID ROLE_ROLLUP_1 ROLE_ROLLUP_2 ROLE_DEPTNAME ROLE_TITLE
      <dbl>  <dbl>         <dbl>         <dbl>         <dbl>      <dbl>
 1    -3.65 -6.28          -2.93         -3.08         -3.16      -3.40
 2    -3.40 -5.62          -2.93         -3.44         -2.17      -3.29
 3    -3.60 -5.40          -2.48         -2.47         -2.50      -2.09
 4    -3.54 -6.34          -2.93         -3.44         -4.27      -2.45
 5    -3.85 -5.59          -2.63         -2.05         -1.29      -2.00
 6    -2.28 -0.949         -2.71         -2.68         -2.12      -2.52
 7    -3.03 -5.84          -2.93         -3.44         -3.98      -2.58
 8    -4.10 -5.51          -2.93         -2.56         -3.26      -2.69
 9    -3.70 -6.00          -2.93         -3.29         -3.07      -2.37
10    -4.00 -5.32          -1.52         -1.51         -2.71      -2.09
# ℹ 32,759 more rows
# ℹ 4 more variables: ROLE_FAMILY_DESC <dbl>, ROLE_FAMILY <dbl>,
#   ROLE_CODE <dbl>, ACTION <fct>
> 
> 
> ## SVM model
> SVM_model <- svm_rbf(rbf_sigma=tune(), cost=tune()) %>% # set or tune
+   set_mode("classification") %>%
+   set_engine("kernlab")
> 
> SVM_wf <- workflow() %>%
+   add_recipe(SVM_recipe) %>%
+   add_model(SVM_model)
> 
> ## Tune smoothness and Laplace here
> 
> 
> ## Set up grid of tuning values
> tuning_grid <- grid_regular(rbf_sigma(),
+                             cost(),
+                             levels = 5) ## L^2 total tuning possibilities
> 
> ## Set up K-fold CV
> folds <- vfold_cv(trainCsv, v = 3, repeats=1)
> 
> ## Run the CV
> ## smoothness 1.5, Laplace 0
> CV_results <- SVM_wf %>%
+   tune_grid(resamples=folds,
+             grid=tuning_grid,
+             metrics=metric_set(roc_auc)) #Or leave metrics NULL
> 
> ## Find best tuning parameters
> collect_metrics(CV_results) %>% # Gathers metrics into DF
+   filter(.metric=="roc_auc") %>%
+   ggplot(data=., aes(x=rbf_sigma, y=mean, color=factor(cost))) +
+   geom_line()
> 
> collect_metrics(CV_results)
# A tibble: 25 × 8
       cost    rbf_sigma .metric .estimator  mean     n std_err .config         
      <dbl>        <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>           
 1 0.000977 0.0000000001 roc_auc binary     0.823     3 0.0131  Preprocessor1_M…
 2 0.000977 0.0000000316 roc_auc binary     0.815     3 0.0110  Preprocessor1_M…
 3 0.000977 0.00001      roc_auc binary     0.814     3 0.0108  Preprocessor1_M…
 4 0.000977 0.00316      roc_auc binary     0.813     3 0.0108  Preprocessor1_M…
 5 0.000977 1            roc_auc binary     0.583     3 0.00839 Preprocessor1_M…
 6 0.0131   0.0000000001 roc_auc binary     0.823     3 0.0131  Preprocessor1_M…
 7 0.0131   0.0000000316 roc_auc binary     0.815     3 0.0109  Preprocessor1_M…
 8 0.0131   0.00001      roc_auc binary     0.814     3 0.0108  Preprocessor1_M…
 9 0.0131   0.00316      roc_auc binary     0.812     3 0.0111  Preprocessor1_M…
10 0.0131   1            roc_auc binary     0.644     3 0.0110  Preprocessor1_M…
# ℹ 15 more rows
> 
> 
> ## Find Best Tuning Parameters
> bestTune <- CV_results %>%
+   select_best("roc_auc")
> bestTune
# A tibble: 1 × 3
    cost    rbf_sigma .config              
   <dbl>        <dbl> <chr>                
1 0.0131 0.0000000001 Preprocessor1_Model06
> 
> ## Finalize the Workflow & fit it
> final_wf <- SVM_wf %>%
+   finalize_workflow(bestTune) %>%
+   fit(data=trainCsv)
maximum number of iterations reached 3.67691e-05 -3.67691e-05> 
> SVM_predictions <- final_wf %>%
+   predict(new_data = testCsv,
+           type = "prob")
> 
> Sub4 <- SVM_predictions %>% 
+   bind_cols(testCsv) %>% 
+   select(id,.pred_1) %>%
+   rename(Id= id, Action = .pred_1)
> 
> 
> write_csv(Sub4, "SVMSubmission.csv")
> 
> stopCluster(cl)
> 
> proc.time()
    user   system  elapsed 
 437.890   24.072 1259.219 
