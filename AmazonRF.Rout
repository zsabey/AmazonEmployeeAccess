
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##Libraries
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.3     ✔ readr     2.1.4
✔ forcats   1.0.0     ✔ stringr   1.5.0
✔ ggplot2   3.4.3     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.0
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> library(tidymodels)
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5     ✔ rsample      1.2.0
✔ dials        1.2.0     ✔ tune         1.1.2
✔ infer        1.0.5     ✔ workflows    1.1.3
✔ modeldata    1.2.0     ✔ workflowsets 1.0.1
✔ parsnip      1.1.1     ✔ yardstick    1.2.0
✔ recipes      1.0.8     
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ scales::discard() masks purrr::discard()
✖ dplyr::filter()   masks stats::filter()
✖ recipes::fixed()  masks stringr::fixed()
✖ dplyr::lag()      masks stats::lag()
✖ yardstick::spec() masks readr::spec()
✖ recipes::step()   masks stats::step()
• Use suppressPackageStartupMessages() to eliminate package startup messages
> library(embed)
> 
> trainCsv <- read_csv("train.csv")
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> testCsv <- read_csv("test.csv")
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> trainCsv <- trainCsv %>%
+   mutate(ACTION = as.factor(ACTION))
> 
> #Create the recipe and bake it
> 
> rf_recipe <- recipe(ACTION ~ ., data=trainCsv) %>%
+   step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors
+   step_other(all_nominal_predictors(), threshold = .001) %>% # combines categorical values that occur <5% into an "other" value
+   step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION))
> 
> prep <- prep(rf_recipe)
> baked <- bake(prep, new_data = NULL)
> baked
# A tibble: 32,769 × 10
   RESOURCE MGR_ID ROLE_ROLLUP_1 ROLE_ROLLUP_2 ROLE_DEPTNAME ROLE_TITLE
      <dbl>  <dbl>         <dbl>         <dbl>         <dbl>      <dbl>
 1    -2.72  -5.33         -2.93         -3.08         -3.18      -3.40
 2    -2.72  -2.76         -2.93         -3.43         -2.19      -3.27
 3    -2.72  -2.76         -2.46         -2.47         -2.50      -2.10
 4    -2.72  -5.39         -2.93         -3.43         -4.19      -2.45
 5    -2.72  -2.76         -2.62         -2.07         -1.36      -2.05
 6    -2.72  -2.76         -2.67         -2.67         -2.13      -2.53
 7    -3.03  -2.76         -2.93         -3.43         -2.41      -2.60
 8    -2.72  -2.76         -2.93         -2.56         -3.26      -2.75
 9    -2.72  -2.76         -2.93         -3.28         -3.10      -2.38
10    -2.72  -2.76         -1.51         -1.53         -2.72      -2.10
# ℹ 32,759 more rows
# ℹ 4 more variables: ROLE_FAMILY_DESC <dbl>, ROLE_FAMILY <dbl>,
#   ROLE_CODE <dbl>, ACTION <fct>
> 
> 
> 
> #Set up the model
> my_mod <- rand_forest(mtry = tune(),
+                       min_n=tune(),
+                       trees=500) %>%
+ set_engine("ranger") %>%
+ set_mode("classification")
> 
> ## Create a workflow with model & recipe
> rf_workflow <- workflow() %>%
+   add_recipe(rf_recipe) %>%
+   add_model(my_mod)
> 
> ## Set up grid of tuning values
> tuning_grid <- grid_regular(mtry(range = c(1,4)),
+                             min_n(),
+                             levels = 10) ## L^2 total tuning possibilities
> 
> ## Set up K-fold CV
> folds <- vfold_cv(trainCsv, v = 3, repeats=1)
> 
> ## Run the CV
> CV_results <- rf_workflow %>%
+   tune_grid(resamples=folds,
+             grid=tuning_grid,
+             metrics=metric_set(roc_auc, f_meas, sens, recall, spec,
+                                precision, accuracy)) #Or leave metrics NULL
→ A | warning: Model failed to converge with max|grad| = 0.176274 (tol = 0.002, component 1), Model is nearly unidentifiable: very large eigenvalue
                - Rescale variables?
There were issues with some computations   A: x1
There were issues with some computations   A: x1

> 
> ## Find best tuning parameters
> collect_metrics(CV_results) %>% # Gathers metrics into DF
+   filter(.metric=="roc_auc") %>%
+   ggplot(data=., aes(x=mtry, y=min_n, color=factor(mtry))) +
+   geom_line()
> 
> collect_metrics(CV_results)
# A tibble: 280 × 8
    mtry min_n .metric   .estimator   mean     n  std_err .config              
   <int> <int> <chr>     <chr>       <dbl> <int>    <dbl> <chr>                
 1     1     2 accuracy  binary     0.945      3 0.00198  Preprocessor1_Model01
 2     1     2 f_meas    binary     0.167      3 0.0111   Preprocessor1_Model01
 3     1     2 precision binary     0.696      3 0.0506   Preprocessor1_Model01
 4     1     2 recall    binary     0.0954     3 0.00770  Preprocessor1_Model01
 5     1     2 roc_auc   binary     0.850      3 0.00381  Preprocessor1_Model01
 6     1     2 sens      binary     0.0954     3 0.00770  Preprocessor1_Model01
 7     1     2 spec      binary     0.997      3 0.000669 Preprocessor1_Model01
 8     2     2 accuracy  binary     0.949      3 0.00143  Preprocessor1_Model02
 9     2     2 f_meas    binary     0.384      3 0.00979  Preprocessor1_Model02
10     2     2 precision binary     0.634      3 0.0257   Preprocessor1_Model02
# ℹ 270 more rows
> 
> CV_results
# Tuning results
# 3-fold cross-validation 
# A tibble: 3 × 4
  splits                id    .metrics           .notes          
  <list>                <chr> <list>             <list>          
1 <split [21846/10923]> Fold1 <tibble [280 × 6]> <tibble [1 × 3]>
2 <split [21846/10923]> Fold2 <tibble [280 × 6]> <tibble [0 × 3]>
3 <split [21846/10923]> Fold3 <tibble [280 × 6]> <tibble [0 × 3]>

There were issues with some computations:

  - Warning(s) x1: Model failed to converge with max|grad| = 0.176274 (tol = 0.002, ...

Run `show_notes(.Last.tune.result)` for more information.
> ## Find Best Tuning Parameters
> bestTune <- CV_results %>%
+   select_best("roc_auc")
> bestTune
# A tibble: 1 × 3
   mtry min_n .config              
  <int> <int> <chr>                
1     2     2 Preprocessor1_Model02
> 
> ## Finalize the Workflow & fit it
> final_wf <- rf_workflow %>%
+   finalize_workflow(bestTune) %>%
+   fit(data=trainCsv)
> 
> rf_predictions <- final_wf %>%
+   predict(new_data = testCsv,
+           type = "prob")
> 
> Sub3 <- rf_predictions %>% 
+   bind_cols(testCsv) %>% 
+   select(id,.pred_1) %>%
+   rename(Id= id, Action = .pred_1)
> 
> 
> write_csv(Sub3, "RFSubmission.csv")
> 
> 
> 
> proc.time()
    user   system  elapsed 
1613.915   33.943  873.541 
